{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 1: Getting the Data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################\n",
    "import myauz\n",
    "from myauz.myalpha_funcs import (\n",
    "    read_data,\n",
    "    persist_data,\n",
    "    update_csv,\n",
    "    compose_portfolio,\n",
    "    retrieveDF,\n",
    "    string2date,\n",
    "    retrievePF,\n",
    "    initialize_df,\n",
    "    time_sleep,\n",
    "    create_path_list,\n",
    "    refresh_db,\n",
    "    get_daily_symbol,\n",
    ")\n",
    "\n",
    "from myauz.myalpha_optimize import (\n",
    "    pf_filtered,\n",
    "    symbol_list_filtered,\n",
    "    determine_earliest_notation,\n",
    "    calc_weights,\n",
    "    get_ret_vol_sr,\n",
    "    neg_sharpe,\n",
    "    check_sum,\n",
    "    minimize_volatility,\n",
    ")\n",
    "\n",
    "\n",
    "#import importlib\n",
    "#importlib.reload(myauz.myalpha_funcs)\n",
    "\n",
    "from myauz.myalpha_libs_universal import StocksDb\n",
    "\n",
    "import pprint\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "#from datetime import datetime\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns \n",
    "sns.set()\n",
    "#sns.reset_orig\n",
    "plt.figure()\n",
    "plt.title(\"total position of portfolio\")\n",
    "# Turn on the minor TICKS, which are required for the minor GRID\n",
    "plt.minorticks_on()\n",
    "# Customize the major grid\n",
    "plt.grid(which='major', linestyle='-', linewidth='0.5', color='dimgray')\n",
    "# Customize the minor grid\n",
    "plt.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphaDB = StocksDb()\n",
    "alphaDB.check_path()\n",
    "print(\"\\n\", alphaDB.api_key_alpha)\n",
    "\n",
    "\n",
    "api_key_alpha = alphaDB.api_key_alpha\n",
    "root_path = alphaDB.path\n",
    "print('root_path: ',root_path)\n",
    "\n",
    "read_from_alphavantage = True\n",
    "rename_column = True\n",
    "\n",
    "\n",
    "usecols = [\"timestamp\", \"close\"]\n",
    "startd = \"2020-01-01\"\n",
    "# endd = \"2020-12-31\"\n",
    "#from datetime import datetime\n",
    "endd = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "print('usecols:', usecols)\n",
    "print('startd',startd)\n",
    "print('endd',endd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symbol_list_full_refresh = [\n",
    "    \"SPY\",\n",
    "]\n",
    "full_refresh_alphavantage = False\n",
    "\n",
    "refresh_db(root_path, api_key_alpha, symbol_list_full_refresh, full_refresh_alphavantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importcsv data from alpha_vantage from scratch (everything since year 2000) and store it in data folder\n",
    "#create a data folder\n",
    "#example: import csv data for Procter&Gamble and SPY (etf which mimicks S&P 500 index)\n",
    "#you alway need to import and store a symbol once you can work with its csv.\n",
    "#if you don't the ticker symbol use alpha vantage for google sheets functionality (extension)\n",
    "#after importing extension and registered you api_key use formula =AVSearchEquitySymbol(\"<some symbol_description\")\n",
    "#example: =AVSearchEquitySymbol(\"bayer\") this will output for example the ticker-symbol: BAYN.DEX\n",
    "\n",
    "symbol_list = [\n",
    "   \"MSFT\",\n",
    "   \"GOOG\",    \n",
    "   \"DHR\",\n",
    "   \"EMR\",\n",
    "   \"ATR\",\n",
    "]\n",
    "\n",
    "# persist_data(symbol_list_full_refresh, _dict, _path_list)\n",
    "\n",
    "refresh_db(root_path, api_key_alpha, symbol_list, full_refresh_alphavantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list = [\n",
    "   \"NVS\",\n",
    "   \"NVZMY\",    \n",
    "   \"CL\",\n",
    "   \"MCD\",    \n",
    "   \"HEINY\",\n",
    "]\n",
    "\n",
    "# persist_data(symbol_list_full_refresh, _dict, _path_list)\n",
    "\n",
    "refresh_db(root_path, api_key_alpha, symbol_list, full_refresh_alphavantage)\n",
    "\n",
    "symbol_list = [\n",
    "   \"HXGBY\",\n",
    "   \"LDSVF\", \n",
    "]\n",
    "\n",
    "# persist_data(symbol_list_full_refresh, _dict, _path_list)\n",
    "\n",
    "refresh_db(root_path, api_key_alpha, symbol_list, full_refresh_alphavantage)\n",
    "\n",
    "\n",
    "# see if specific symbol exists in alpha-vantage db\n",
    "\"\"\"\n",
    "\n",
    "symbol = \"4GP.FRK\"\n",
    "function=\"TIME_SERIES_DAILY_ADJUSTED\"\n",
    "url = f\"https://www.alphavantage.co/query?function={function}&symbol={symbol}&outputsize=full&apikey={api_key_alpha}&datatype=csv\"\n",
    "_df = pd.read_csv(url)\n",
    "_df.head()Â¿\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol_list_short = [\n",
    "    \"PG\",\n",
    "    \"AMZN\",\n",
    "]\n",
    "\n",
    "\n",
    "refresh_db(root_path, api_key_alpha, symbol_list_short, full_refresh_alphavantage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#symbol_list = [\"DHR\", \"GOOG\"]\n",
    "\n",
    "symbol_list = [\n",
    "   \"MSFT\",\n",
    "   \"GOOG\",    \n",
    "   \"DHR\",\n",
    "   \"EMR\",\n",
    "   \"ATR\",\n",
    "   \"HXGBY\",\n",
    "   \"NVS\",\n",
    "   \"NVZMY\",    \n",
    "   \"CL\",\n",
    "   \"MCD\",    \n",
    "   \"HEINY\",\n",
    "   \"LDSVF\",  \n",
    "]\n",
    "\n",
    "path_list = create_path_list(symbol_list, root_path)\n",
    "pprint.pprint(path_list)\n",
    "\n",
    "bool_list_all = [\n",
    "   True, #\"MSFT\", microsoft    \n",
    "   True, #\"GOOG\", alphabet google      \n",
    "#  True, #\"AMZN\", amazon\n",
    "   True, #\"DHR\", danaher\n",
    "   True, #\"EMR\", emerson    \n",
    "   True, #\"ATR\", aptargroup\n",
    "   True, #\"HXGBY\", hexagon\n",
    "   True, #\"NVS\", novartis\n",
    "   True, #\"NVZMY\", novozymes    \n",
    "   True, #\"CL\", colgate palmolive\n",
    "   True, #\"MCD\", mcdonalds    \n",
    "   True, #\"HEINY\", heineken\n",
    "   True, #\"LDSVF\", lindt & spruengli    \n",
    "]\n",
    "\n",
    "bool_list_high_tech = [\n",
    "   True, #\"MSFT\", microsoft    \n",
    "   True, #\"GOOG\", alphabet google      \n",
    "#  True, #\"AMZN\", amazon\n",
    "   False, #\"DHR\", danaher\n",
    "   False, #\"EMR\", emerson    \n",
    "   False, #\"ATR\", aptargroup\n",
    "   False, #\"HXGBY\", hexagon\n",
    "   False, #\"NVS\", novartis\n",
    "   False, #\"NVZMY\", novozymes    \n",
    "   False, #\"CL\", colgate palmolive\n",
    "   False, #\"MCD\", mcdonalds    \n",
    "   False, #\"HEINY\", heineken\n",
    "   False, #\"LDSVF\", lindt & spruengli    \n",
    "]\n",
    "\n",
    "bool_list_industry = [\n",
    "   False, #\"MSFT\", microsoft    \n",
    "   False, #\"GOOG\", alphabet google      \n",
    "#  False, #\"AMZN\", amazon\n",
    "   True, #\"DHR\", danaher\n",
    "   True, #\"EMR\", emerson    \n",
    "   True, #\"ATR\", aptargroup\n",
    "   True, #\"HXGBY\", hexagon\n",
    "   True, #\"NVS\", novartis\n",
    "   True, #\"NVZMY\", novozymes    \n",
    "   False, #\"CL\", colgate palmolive\n",
    "   False, #\"MCD\", mcdonalds    \n",
    "   False, #\"HEINY\", heineken\n",
    "   False, #\"LDSVF\", lindt & spruengli    \n",
    "]\n",
    "\n",
    "bool_list_consumer = [\n",
    "   False, #\"MSFT\", microsoft    \n",
    "   False, #\"GOOG\", alphabet google      \n",
    "#  False, #\"AMZN\", amazon\n",
    "   False, #\"DHR\", danaher\n",
    "   False, #\"EMR\", emerson    \n",
    "   False, #\"ATR\", aptargroup\n",
    "   False, #\"HXGBY\", hexagon\n",
    "   False, #\"NVS\", novartis\n",
    "   False, #\"NVZMY\", novozymes    \n",
    "   True, #\"CL\", colgate palmolive\n",
    "   True, #\"MCD\", mcdonalds    \n",
    "   True, #\"HEINY\", heineken\n",
    "   True, #\"LDSVF\", lindt & spruengli    \n",
    "]\n",
    "\n",
    "colors = [\n",
    "    'magenta',\n",
    "    'lime',\n",
    "#   'orange',\n",
    "    'blue',\n",
    "    'black',\n",
    "    'slategrey',\n",
    "    'brown',\n",
    "    'olive',\n",
    "    'darkviolet',\n",
    "    'red',\n",
    "    'turquoise',\n",
    "    'forestgreen',\n",
    "    'gold',\n",
    "]\n",
    "\n",
    "color_dict = dict(zip(symbol_list, colors))\n",
    "print('\\n')\n",
    "print(color_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### create dataframe with portfolio adjusted close\n",
    "usecols = [\"timestamp\", \"close\"]\n",
    "pf = retrievePF(symbol_list, path_list, startd, endd, usecols, rename_column)\n",
    "print(pf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#startd_new = string2date('2020-07-01')\n",
    "#endd_new = string2date('2020-08-01')\n",
    "\n",
    "\n",
    "startd = '2020-01-01'\n",
    "included = bool_list_high_tech\n",
    "#pf1 = pf.loc[startd:,:]\n",
    "#pf1 = pf.loc[startd:,bool_list_consumer]\n",
    "#pf1_vol = pf_vol.loc[startd:,:]\n",
    "#pf1_vol = pf_vol.loc[startd:,bool_list_consumer]\n",
    "pf1 = pf_filtered(pf,startd,included)\n",
    "pf2 = pf_filtered(pf,startd,bool_list_industry)\n",
    "pf3 = pf_filtered(pf,startd,bool_list_consumer)\n",
    "pprint.pprint(pf1.head(3))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____\n",
    "## Cumulative Daily Returns\n",
    "\n",
    "Great! Now we can see which stock was the most wide ranging in daily returns (you should have realized it was Tesla, our original stock price plot should have also made that obvious).\n",
    "\n",
    "With daily cumulative returns, the question we are trying to answer is the following, if I invested $1 in the company at the beginning of the time series, how much would is be worth today? This is different than just the stock price at the current day, because it will take into account the daily returns. Keep in mind, our simple calculation here won't take into account stocks that give back a dividend. Let's look at some simple examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets us say there is a stock 'ABC' that is being actively traded on an exchange. ABC has the following prices corresponding to the dates given"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Date                        Price\n",
    "    01/01/2018                   10\n",
    "    01/02/2018                   15\n",
    "    01/03/2018                   20\n",
    "    01/04/2018                   25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Daily Return** : Daily return is the profit/loss made by the stock compared to the previous day. (This is what ew just calculated above). A value above one indicates profit, similarly a value below one indicates loss. It is also expressed in percentage to convey the information better. (When expressed as percentage, if the value is above 0, the stock had give you profit else loss). So for the above example the daily returns would be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Date                         Daily Return                  %Daily Return\n",
    "    01/01/2018                 10/10 =  1                          -   \n",
    "    01/02/2018                 15/10 =  3/2                       50%\n",
    "    01/03/2018                 20/15 =  4/3                       33%\n",
    "    01/04/2018                 25/20 =  5/4                       20%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cumulative Return**: While daily returns are useful, it doesn't give the investor a immediate insight into the gains he had made till date, especially if the stock is very volatile. Cumulative return is computed relative to the day investment is made.  If cumulative return is above one, you are making profits else you are in loss. So for the above example cumulative gains are as follows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Date                       Cumulative Return         %Cumulative Return\n",
    "    01/01/2018                  10/10 =  1                         100 %   \n",
    "    01/02/2018                  15/10 =  3/2                       150 %\n",
    "    01/03/2018                  20/10 =  2                         200 %\n",
    "    01/04/2018                  25/10 =  5/2                       250 %"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for a cumulative daily return is:\n",
    "\n",
    "$ i_i = (1+r_t) * i_{t-1} $\n",
    "\n",
    "Here we can see we are just multiplying our previous investment at i at t-1 by 1+our percent returns. Pandas makes this very simple to calculate with its cumprod() method. Using something in the following manner:\n",
    "\n",
    "    df[daily_cumulative_return] = ( 1 + df[pct_daily_return] ).cumprod()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Create a cumulative daily return column for each car company's dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tesla['returns']\n",
    "#(1+tesla['returns'])\n",
    "#(1+tesla['returns']).cumprod()\n",
    "df_returns = (pf/pf.shift(1))-1\n",
    "pprint.pprint(df_returns['MSFT'])\n",
    "print('\\n')\n",
    "(1+df_returns['MSFT']).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tesla['cumRet']=(1+tesla['returns']).cumprod()\n",
    "#tesla.head(10)\n",
    "#gm['cumRet']=(1+gm['returns']).cumprod()\n",
    "#ford['cumRet']=(1+ford['returns']).cumprod()\n",
    "\n",
    "df_cumReturns = initialize_df(symbol_list, startd, endd)\n",
    "df_cumReturns = (1+df_returns).cumprod()\n",
    "df_cumReturns.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tesla['cumRet'].plot(label='Tesla', figsize=(16,8))\n",
    "#gm['cumRet'].plot(label='gm', figsize=(16,8))\n",
    "#ford['cumRet'].plot(label='Ford', figsize=(16,8));\n",
    "import seaborn as sns \n",
    "sns.set()\n",
    "#sns.reset_orig\n",
    "plt.figure()\n",
    "\n",
    "color_list = [color_dict.get(x, _) for x in pf.columns]\n",
    "df_cumReturns.plot(label='Acum.Returns',color=color_list,figsize=(16,8))\n",
    "plt.hlines(1, startd,endd,colors='blue', linestyles='--')\n",
    "plt.legend(loc=2);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "color_list = [color_dict.get(x, _) for x in pf1.columns]\n",
    "df_cumReturns[['MSFT','GOOG']].plot(label='Acum.Returns',color=color_list,figsize=(16,8))\n",
    "plt.hlines(1, startd,endd,colors='blue', linestyles='--')\n",
    "plt.legend(loc=2);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(pf / pf.iloc[0] * 100).plot(figsize=(16, 8))\n",
    "plt.hlines(100, startd,endd,colors='blue', linestyles='--')\n",
    "plt.legend(loc=2);\n",
    "\n",
    "color_list = [color_dict.get(x, _) for x in ['NVS','HEINY','EMR']]\n",
    "(pf[['NVS','HEINY','EMR']] / pf[['NVS','HEINY','EMR']].iloc[0] * 100).plot(color=color_list,figsize=(16, 8))\n",
    "plt.hlines(100, startd,endd,colors='blue', linestyles='--')\n",
    "plt.legend(loc=2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_returns.head()\n",
    "sns.reset_orig()\n",
    "\n",
    "color_list = [color_dict.get(x, _) for x in df_returns.columns]\n",
    "\n",
    "color_list\n",
    "\n",
    "df_returns.plot(color=color_list, figsize=(16,8));\n",
    "(df_returns / df_returns.iloc[1]).plot(color=color_list,figsize=(16,8), alpha=0.9);\n",
    "\n",
    "(df_returns[['HEINY']] / df_returns[['HEINY']].iloc[1]).plot(color='forestgreen',figsize=(16,8));\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [color_dict.get(x, _) for x in ['ATR','HXGBY','NVS','NVZMY','CL','MCD']]\n",
    "(df_returns[['ATR','HXGBY','NVS','NVZMY','CL','MCD']] / df_returns[['ATR','HXGBY','NVS','NVZMY','CL','MCD']].iloc[1]).plot(color=color_list,figsize=(16,8), alpha=0.9);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [color_dict.get(x, _) for x in ['ATR','HXGBY','NVS','NVZMY','MCD']]\n",
    "(df_returns[['ATR','HXGBY','NVS','NVZMY','MCD']] / df_returns[['ATR','HXGBY','NVS','NVZMY','MCD']].iloc[1]).plot(color=color_list,figsize=(16,8), alpha=0.9);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now plot the Cumulative Return columns against the time series index. Which stock showed the highest return for a $1 invested? Which showed the lowest?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [color_dict.get(x, _) for x in ['ATR','HXGBY','NVZMY']]\n",
    "(df_returns[['ATR','HXGBY','NVZMY']] / df_returns[['ATR','HXGBY','NVZMY']].iloc[1]).plot(color=color_list,figsize=(16,8), alpha=0.6);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_list = [color_dict.get(x, _) for x in ['HXGBY','NVZMY']]\n",
    "(df_returns[['HXGBY','NVZMY']] / df_returns[['HXGBY','NVZMY']].iloc[1]).plot(color=color_list,figsize=(16,8), alpha=0.6);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!\n",
    "\n",
    "That is it for thsi very basic analysis, this concludes this half of the course, which focuses much more on learning the tools of the trade. The second half of the course is where we really dive into functionality designed for time series, quantitative analysis, algorithmic trading, and much more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del [_df]\n",
    "#gc.collect()\n",
    "#_df=pd.DataFrame()\n",
    "symbol_list = [\n",
    "   \"MSFT\",\n",
    "   \"GOOG\",    \n",
    "   \"AMZN\",    \n",
    "   \"DHR\",\n",
    "   \"EMR\",\n",
    "   \"ATR\",\n",
    "   \"HXGBY\",\n",
    "   \"NVS\",\n",
    "   \"NVZMY\",    \n",
    "   \"CL\",\n",
    "   \"MCD\",    \n",
    "   \"HEINY\",\n",
    "   \"LDSVF\",  \n",
    "]\n",
    "\n",
    "usecols = [\"timestamp\", \"close\"]\n",
    "\n",
    "path_list = create_path_list(symbol_list, root_path)\n",
    "pprint.pprint(path_list)\n",
    "df_aux1 = retrievePF(symbol_list, path_list, startd, endd,usecols)\n",
    "df_aux1.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('root_path:',root_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Sharpe RATIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "symbol_list=['AAPL','AMZN','CSCO','MSFT']\n",
    "startd='2012-01-01'\n",
    "endd='2017-01-01'\n",
    "for symbol in symbol_list:\n",
    "    if symbol == 'AAPL':\n",
    "        aapl = get_daily_symbol(symbol,root_path,startd,endd)\n",
    "        print(\"symbol: \" + symbol)\n",
    "\n",
    "    elif symbol == 'AMZN':\n",
    "        amzn = get_daily_symbol(symbol,root_path,startd,endd)\n",
    "        print(\"symbol: \" + symbol)\n",
    "  \n",
    "    elif symbol == 'CSCO':\n",
    "        csco = get_daily_symbol(symbol,root_path,startd,endd)\n",
    "        print(\"symbol: \" + symbol)\n",
    " \n",
    "    elif symbol == 'MSFT':\n",
    "        msft = get_daily_symbol(symbol,root_path,startd,endd)\n",
    "        print(\"symbol: \" + symbol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl.iloc[0]['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cumulative returns:\n",
    "for stock in (aapl, csco, amzn, msft):\n",
    "    stock['cum_return'] = stock['close'] / stock.iloc[0]['close']\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of tuples (first element is the dataframe of the stock and second element is 0.3)\n",
    "list(zip((aapl, csco, amzn, msft), [.3, .2, .4, .1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocation to portfolio\n",
    "# 30% aapl\n",
    "# 20% amzn\n",
    "# 40% csco\n",
    "# 10% msft\n",
    "aapl.head()\n",
    "for stock, weight in zip((aapl, csco, amzn, msft), [.3, .2, .4, .1]):\n",
    "    stock['weight'] = stock['cum_return']*weight\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl.head()\n",
    "# 30% of my money is in apple so this is my cum return portfolio wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#investing 1Mio $ - calculate the position value of each stock according to its weight in the portfolio\n",
    "for stock in (aapl, csco, amzn, msft):\n",
    "    stock['pos_value'] = stock['weight']*100000\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos_vals = [aapl['pos_value'], csco['pos_value'], amzn['pos_value'], msft['pos_value']]\n",
    "#all_pos_vals\n",
    "pf = pd.concat(all_pos_vals, axis = 1)\n",
    "pf.columns = ['aapl', 'csco', 'amzn', 'msft']\n",
    "pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total position\n",
    "pf['total_pos']=pf.sum(axis=1)\n",
    "pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf['total_pos'].plot(figsize=(10,8))\n",
    "plt.title('total portfolio value ');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.drop('total_pos', axis = 1).plot(figsize=(10,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf['daily_return']= pf['total_pos'].pct_change(1)\n",
    "pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf['daily_return'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf['daily_return'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf['daily_return'].plot(kind='kde', figsize=(16,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_return = 100 * ((pf['total_pos'][-1] - pf['total_pos'][0])/pf['total_pos'][0] )\n",
    "cum_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf['total_pos'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate sharpe ratio assume risk-free rate to be zero\n",
    "sharp_ratio = pf['daily_return'].mean() / pf['daily_return'].std()\n",
    "sharp_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annualize thi sr \n",
    "# asr should be above 1 \n",
    "\n",
    "sharp_ratio_annual = (252**0.5)*sharp_ratio\n",
    "sharp_ratio_annual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# portfolio optimization\n",
    "# - monte carlo\n",
    "# - mathematical optimization by minimizing the negative sharpe ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pd.concat([aapl['close'],csco['close'],amzn['close'], msft['close']], axis=1)\n",
    "\n",
    "pf.columns = ['aapl', 'csco', 'amzn', 'msft']\n",
    "\n",
    "pf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate annual mean of returns as % \n",
    "pf.pct_change(1).mean()*252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.pct_change(1).corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use log returns for algorithms especially for normalizations\n",
    "log_ret= np.log(pf/pf.shift(1))\n",
    "\n",
    "log_ret.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret.hist(bins=100, figsize=(12,8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret.var()*252\n",
    "#log_ret.std()*252**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret.cov() * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "# to keep getting the same random weights\n",
    "\n",
    "print(pf.columns)\n",
    "weights = np.array(np.random.random(4))\n",
    "print(weights)\n",
    "# but they do not add up to 1\n",
    "\n",
    "print('rebalance')\n",
    "weights=weights/np.sum(weights)\n",
    "print(weights)\n",
    "np.sum(weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('expected portfolio return')\n",
    "exp_ret = np.sum((log_ret.mean() * weights) * 252)\n",
    "print((log_ret.mean() * weights) * 252)\n",
    "exp_ret\n",
    "print(exp_ret)\n",
    "print('\\n expected volatility')\n",
    "#denominator of sharp-ratio\n",
    "\n",
    "exp_vol = np.sqrt(np.dot((weights.T),np.dot(log_ret.cov()*252, weights)))\n",
    "print(exp_vol)\n",
    "\n",
    "sr = exp_ret / exp_vol\n",
    "print('\\n sharpe ratio: ')\n",
    "print(sr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(101)\n",
    "num_pf = 5000\n",
    "all_weights = np.zeros((num_pf, len(pf.columns)))\n",
    "ret_arr = np.zeros(num_pf)\n",
    "vol_arr = np.zeros(num_pf)\n",
    "sharpe_arr = np.zeros(num_pf)\n",
    "\n",
    "for ind in range(num_pf):\n",
    "    weights = np.array(np.random.random(4))\n",
    "    weights = weights / np.sum(weights)\n",
    "    all_weights[ind,:] = weights\n",
    "    # expected return\n",
    "    ret_arr[ind] = np.sum((log_ret.mean() * weights) * 252)\n",
    "    #expected volatility\n",
    "    vol_arr[ind] = np.sqrt(np.dot((weights.T),np.dot(log_ret.cov()*252, weights)))\n",
    "    #sharpe ratio\n",
    "    sharpe_arr[ind] = ret_arr[ind] / vol_arr[ind]\n",
    "    \n",
    "print('done')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sharpe_arr.max())\n",
    "sharpe_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharpe_arr.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sharpe_arr[2936])\n",
    "all_weights[2936,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "plt.scatter(vol_arr,ret_arr, c= sharpe_arr, cmap='plasma')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('return')\n",
    "\n",
    "max_sr_ret = ret_arr[2936]\n",
    "max_sr_vol = vol_arr[2936]\n",
    "plt.scatter(max_sr_vol, max_sr_ret,  c='red')\n",
    "           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using ML approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ret_vol_sr(weights):\n",
    "    weights = np.array(weights)\n",
    "    ret = np.sum(log_ret.mean() * weights)  * 252\n",
    "    vol = np.sqrt(np.dot(weights.T, np.dot(log_ret.cov()*252,weights)))\n",
    "    sr = ret / vol\n",
    "    return np.array([ret,vol,sr])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize \n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function\n",
    "#minimize negative sharpe ratio which is the same as maximize sr\n",
    "def neg_sharpe(weights):\n",
    "    return get_ret_vol_sr(weights)[2] * -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_ret.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_sum(weights):\n",
    "    #return 0 if the sum of the weights is 1\n",
    "    return np.sum(weights) - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons = ({'type': 'eq', 'fun':check_sum})\n",
    "#defines a constraint for minimize function - it says\n",
    "# type will be equations and a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = ((0,1),(0,1), (0,1),(0,1))\n",
    "#sum of weights is 1 \n",
    "init_guess = [0.25,0.25,0.25,0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt_results = minimize(neg_sharpe, )\n",
    "help(minimize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_results = minimize(neg_sharpe, init_guess, method='SLSQP', bounds=bounds,constraints=cons )\n",
    "opt_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (np.sum(opt_results.x)) == 1:\n",
    "    print(\"ok\")\n",
    "\n",
    "get_ret_vol_sr(opt_results.x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of possible returns  y-values\n",
    "frontier_y = np.linspace(0,0.3,100)\n",
    "frontier_y\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_volatility(weights):\n",
    "    return get_ret_vol_sr(weights)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_volatility = []\n",
    "#for a possible return what is the risk\n",
    "#in order to get the return/volatility combinations on the efficient frontier \n",
    "#we add the second constraint\n",
    "for possible_return in frontier_y:\n",
    "    cons = ({'type':'eq', 'fun':check_sum},{'type':'eq', 'fun':lambda w: (get_ret_vol_sr(w)[0]-possible_return)})\n",
    "    result = minimize(minimize_volatility, init_guess, method='SLSQP', bounds=bounds, constraints=cons)\n",
    "    frontier_volatility.append(result['fun'])\n",
    "    \n",
    "    \n",
    "#frontier_volatility\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_sr = frontier_y / frontier_volatility\n",
    "print(frontier_sr.max())\n",
    "\n",
    "print(frontier_sr.argmax())\n",
    "\n",
    "max_sr_ret_calc = frontier_y[frontier_sr.argmax()]\n",
    "max_sr_vol_calc = frontier_volatility[frontier_sr.argmax()]\n",
    "print(frontier_volatility[frontier_sr.argmax()])\n",
    "print(frontier_y[frontier_sr.argmax()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated efficient frontier\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(frontier_volatility,frontier_y, 'g--');\n",
    "\n",
    "#scatter-plot from monte carlo simulation\n",
    "plt.scatter(vol_arr,ret_arr, c= sharpe_arr, cmap='plasma')\n",
    "plt.colorbar(label='Sharpe Ratio')\n",
    "plt.xlabel('Volatility')\n",
    "plt.ylabel('return')\n",
    "\n",
    "max_sr_ret = ret_arr[2936]\n",
    "max_sr_vol = vol_arr[2936]\n",
    "print('monte_carlo x-value-max: ', max_sr_vol)\n",
    "print('monte_carlo y-value-max:', max_sr_ret)\n",
    "plt.scatter(max_sr_vol, max_sr_ret,  c='black');\n",
    "plt.axhline(max_sr_ret, color='gray',linestyle='--')\n",
    "plt.axvline(max_sr_vol, color='gray', linestyle='--');\n",
    "\n",
    "max_sr_ret = max_sr_ret_calc\n",
    "max_sr_vol = max_sr_vol_calc\n",
    "print('sharpe ratio x-value-max: ', max_sr_vol)\n",
    "print('sharpe ratio y-value-max:', max_sr_ret)\n",
    "plt.scatter(max_sr_vol, max_sr_ret,  c='red');\n",
    "plt.axhline(max_sr_ret, color='gray',linestyle='--')\n",
    "plt.axvline(max_sr_vol, color='gray', linestyle='--');\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frontier_sr = frontier_y / frontier_volatility\n",
    "print(frontier_sr.max())\n",
    "\n",
    "print(frontier_sr.argmax())\n",
    "\n",
    "print(frontier_volatility[frontier_sr.argmax()])\n",
    "print(frontier_y[frontier_sr.argmax()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "a4aa84e21e498c8dbf4f0e408a60a976e6d22209c7134ecf69ca024138d1bd60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
